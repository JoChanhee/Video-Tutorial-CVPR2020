{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. Inference on your own videos using pre-trained models\n===========================================================\n\nIn this tutorial, we provide a script for you to make human activity predictions on your own videos.\nThe only thing you need to prepare is a text file containing the information of your videos (e.g., the path to your videos),\nwe will take care of the rest.\nYou can use many popular pre-trained models (e.g., I3D, I3D-nonlocal, SlowFast) in a single command line.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Feel free to skip the tutorial because the inference script is self-complete and ready to launch.\n\n    :download:`Download Full Python Script: inference.py<../../../scripts/action-recognition/inference.py>`\n\n    For more command options, please run ``python inference.py -h``\n    Please checkout the `model_zoo <../model_zoo/index.html#action_recognition>`_ to select your preferred pretrained model.</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare Data\n------------\n\nYour data can be stored in any hierarchy.\nThe only thing you need to prepare is a text file, ``video.txt``, which should look like\n\n::\n\n    /home/ubuntu/your_data/video_001.mp4\n    /home/ubuntu/your_data/video_001.mp4\n    /home/ubuntu/your_data/video_002.mp4\n    /home/ubuntu/your_data/video_003.mp4\n    /home/ubuntu/your_data/video_004.mp4\n    ......\n    /home/ubuntu/your_data/video_100.mp4\n\nEach line is the path to each video you want to make predictions.\n\nOr you can also use the format we used for training models in other tutorials,\n::\n\n    /home/ubuntu/your_data/video_001.mp4 200 0\n    /home/ubuntu/your_data/video_001.mp4 300 1\n    /home/ubuntu/your_data/video_002.mp4 100 2\n    /home/ubuntu/your_data/video_003.mp4 400 2\n    /home/ubuntu/your_data/video_004.mp4 200 1\n    ......\n    /home/ubuntu/your_data/video_100.mp4.100 3\n\nEach line has three things, the path to each video, the number of video frames and the video label.\nHowever, the second and third things are not gonna used in the code, they are just a placeholder.\nSo you can put any postive number in these two places.\n\nNote that, at this moment, we only support inferencing on videos directly.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you prepare the ``video.txt``, you can start inferencing on your videos.\nLet's first use I3D models as an example.\n\n::\n\n    python inference.py --data-list video.txt --model i3d_resnet50_v1_kinetics400\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The predictions will be print out to the console and the log will be saved to the current directory.\nYou can find the log as ``predictions.log``.\nIf you want to save the logits (confidence score) to ``.npy`` and use it again later, you can\n\n::\n\n    python inference.py --data-list video.txt --model i3d_resnet50_v1_kinetics400 --save-logits\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to save both the logits and predictions to ``.npy`` and use them again later, you can\n\n::\n\n    python inference.py --data-list video.txt --model i3d_resnet50_v1_kinetics400 --save-logits --save-preds\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to use a strong network, like SlowFast. We support it as well.\nJust change the model name and pick which SlowFast configuration you want to use.\n\n::\n\n    python inference.py --data-list video.txt --model slowfast_4x16_resnet50_kinetics400 --slowfast --slow-temporal-stride 16 --fast-temporal-stride 2 --new-length 64\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we choose the basic slowfast_4x16_resnet50 configuration.\nIt requires the input to be a 64-frame video clip. We select 4 frames for the slow branch (temporal_stride = 16) and 32 frames for the fast branch (temporal_stride = 2).\n\nSimilarly, you can specify num_segments, new_legnth, etc. as in previous tutorial to obtain more accurate predictions.\nThere are many other options and other models you can choose, please check ``inference.py`` for more usage information.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}