{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Extracting video features from pre-trained models\n=======================================================\n\nFeature extraction is a very useful tool when you don't have large annotated dataset or don't have the\ncomputing resources to train a model from scratch for your use case. It's also useful to visualize what the model have learned.\nIn this tutorial, we provide a simple unified solution.\nThe only thing you need to prepare is a text file containing the information of your videos (e.g., the path to your videos),\nwe will take care of the rest.\nYou can extract strong video features from many popular pre-trained models (e.g., I3D, I3D-nonlocal, SlowFast) using a single command line.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Feel free to skip the tutorial because the feature extraction script is self-complete and ready to launch.\n\n    :download:`Download Full Python Script: feat_extract.py<../../../scripts/action-recognition/feat_extract.py>`\n\n    For more command options, please run ``python feat_extract.py -h``\n    Please checkout the `model_zoo <../model_zoo/index.html#action_recognition>`_ to select your preferred pretrained model.</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare Data\n------------\n\nYour data can be stored in any hierarchy.\nThe only thing you need to prepare is a text file, ``video.txt``, which should look like\n\n::\n\n    /home/ubuntu/your_data/video_001.mp4\n    /home/ubuntu/your_data/video_001.mp4\n    /home/ubuntu/your_data/video_002.mp4\n    /home/ubuntu/your_data/video_003.mp4\n    /home/ubuntu/your_data/video_004.mp4\n    ......\n    /home/ubuntu/your_data/video_100.mp4\n\nEach line is the path to each video you want to extract features from.\n\nOr you can also use the format we used for training models in other tutorials,\n::\n\n    /home/ubuntu/your_data/video_001.mp4 200 0\n    /home/ubuntu/your_data/video_001.mp4 300 1\n    /home/ubuntu/your_data/video_002.mp4 100 2\n    /home/ubuntu/your_data/video_003.mp4 400 2\n    /home/ubuntu/your_data/video_004.mp4 200 1\n    ......\n    /home/ubuntu/your_data/video_100.mp4.100 3\n\nEach line has three things, the path to each video, the number of video frames and the video label.\nHowever, the second and third things are not gonna used in the code, they are just a placeholder.\nSo you can put any postive number in these two places.\n\nNote that, at this moment, we only support extracting features from videos directly.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you prepare the ``video.txt``, you can start extracting feature by:\n\n::\n\n    python feat_extract.py --data-list video.txt --model i3d_resnet50_v1_kinetics400 --save-dir ./features\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The extracted features will be saved to the ``features`` directory. Each video will have one feature file.\nFor example, ``video_001.mp4`` will have a feature named ``i3d_resnet50_v1_kinetics400_video_001.mp4_feat.npy``.\nThe feature is extracted from the center of the video by using a 32-frames clip.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want a stronger feature by covering more temporal information. For example, you want to extract features from\n10 segments of the video and combine them. You can do\n\n::\n\n    python feat_extract.py --data-list video.txt --model i3d_resnet50_v1_kinetics400 --save-dir ./features --num-segments 10\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you you want to extract features from 10 segments of the video, select 64-frame clip from each segment,\nand combine them. You can do\n\n::\n\n    python feat_extract.py --data-list video.txt --model i3d_resnet50_v1_kinetics400 --save-dir ./features --num-segments 10 --new-length 64\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you you want to extract features from 10 segments of the video, select 64-frame clip from each segment,\nperform three-cropping technology, and combine them. You can do\n\n::\n\n    python feat_extract.py --data-list video.txt --model i3d_resnet50_v1_kinetics400 --save-dir ./features --num-segments 10 --new-length 64 --three-crop\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also provide pre-trained SlowFast models for you to extract video features. SlowFast is a recent state-of-the-art video model that\nachieves the best accuracy-efficiency tradeoff. For example, if you want to extract features from model ``slowfast_4x16_resnet50_kinetics400``,\n\n::\n\n    python feat_extract.py --data-list video.txt --model slowfast_4x16_resnet50_kinetics400 --save-dir ./features --slowfast --slow-temporal-stride 16 --fast-temporal-stride 2\n\nThe model requires the input to be a 64-frame video clip.\nWe select 4 frames for the slow branch (temporal_stride = 16) and 32 frames for the fast branch (temporal_stride = 2).\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, you can specify num_segments, new_legnth, etc. to obtain stronger features.\nThere are many other options and other models you can choose, please check ``feat_extract.py`` for more usage information.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}