{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "10. Introducing Decord: an efficient video reader\n====================================================\n\nTraining deep neural networks on videos is very time consuming. For example, training a state-of-the-art SlowFast network\non Kinetics400 dataset using a server with 8 V100 GPUs takes more than 10 days. Slow training causes long research cycles\nand is not friendly for new comers and students to work on video related problems. There are several reasons causing the slowness,\nbig batch of data, inefficiency of video reader and huge model computation.\n\nAnother troubling matter is the complex data preprocessing and huge storage cost. Take Kinetics400 dataset as an example, this dataset\nhas about 240K training and 20K validation videos. All the videos take 450G disk space.\nHowever, if we decode the videos to frames and use image loader to train the model, the decoded frames will take 6.8T disk space, which\nis unacceptable to most people. In addition, the decoding process is slow. It takes 1.5 days using 60 workers to decode all the videos to frames.\nIf we use 8 workers (as in common laptop or standard workstation), it will take a week to perform such data preprocessing even before your actual training.\n\nGiven the challenges aforementioned, in this tutotial, we introduce a new video reader, `Decord <https://github.com/zhreshold/decord>`_.\nDecord is efficient and flexible. It provides convenient video slicing methods based on a wrapper on top of hardware accelerated video decoders,\ne.g. FFMPEG/LibAV and Nvidia Codecs. It is designed to handle awkward video shuffling experience in order to provide smooth experiences\nsimilar to random image loader for deep learning. In addition, it works cross-platform, e.g., Linux, Windows and Mac OS.\nWith the new video reader, you don't need to decode videos to frames anymore, just start training on your video dataset with even higher training speed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install\n-------\n\nDecord is easy to install, just\n::\n\n    pip install decord\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Usage\n-----\n\nWe provide some usage cases here to get you started. For complete API, please refer to official documentation.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we want to read a video. Let's download the example video first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gluoncv import utils\nurl = 'https://github.com/bryanyzhu/tiny-ucf101/raw/master/abseiling_k400.mp4'\nvideo_fname = utils.download(url)\n\nfrom decord import VideoReader\nvr = VideoReader(video_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to load the video in a specific dimension so that it can be fed into a CNN for processing,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vr = VideoReader(video_fname, width=320, height=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have loaded the video, if we want to know how many frames are there in the video,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "duration = len(vr)\nprint('The video contains %d frames' % duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to access frame at index 10,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "frame = vr[9]\nprint(frame.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For deep learning, usually we want to get multiple frames at once. Now you can use ``get_batch`` function,\nSuppose we want to get a 32-frame video clip by skipping one frame in between,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "frame_id_list = range(0, 64, 2)\nframes = vr.get_batch(frame_id_list).asnumpy()\nprint(frames.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is another advanced functionality, you can get all the key frames as below,\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "key_indices = vr.get_key_indices()\nkey_frames = vr.get_batch(key_indices)\nprint(key_frames.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pretty flexible, right? Try it on your videos.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Speed comparison\n----------------\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we want to compare its speed with Opencv VideoCapture to demonstrate its efficiency.\nLet's load the same video and get all the frames randomly using both decoders to compare their performance.\nWe will run the loading for 11 times: use the first one as warming up, and average the rest 10 runs as the average speed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cv2\nimport time\nimport numpy as np\n\nframes_list = np.arange(duration)\nnp.random.shuffle(frames_list)\n\n# Decord\nfor i in range(11):\n    if i == 1:\n        start_time = time.time()\n    decord_vr = VideoReader(video_fname)\n    frames = decord_vr.get_batch(frames_list)\nend_time = time.time()\nprint('Decord takes %4.4f seconds.' % ((end_time - start_time)/10))\n\n# OpenCV\nfor i in range(11):\n    if i == 1:\n        start_time = time.time()\n    cv2_vr = cv2.VideoCapture(video_fname)\n    for frame_idx in frames_list:\n        cv2_vr.set(1, frame_idx)\n        _, frame = cv2_vr.read()\n    cv2_vr.release()\nend_time = time.time()\nprint('OpenCV takes %4.4f seconds.' % ((end_time - start_time)/10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that Decord is 2x faster than OpenCV VideoCapture.\nWe also compare with `Pyav container <https://github.com/mikeboers/PyAV>`_ and demonstrate 2x speed up as well.\n\nIn conclusion, Decord is an efficient and flexible video reader. It supports get_batch, GPU loading, fast random access, etc, which is\nperfectly designed for training video deep neural networks. We use Decord in our video model training for large-scale datasets and observe\nsimilar speed as using image loaders on decoded video frames. This significanly reduces the data preprocessing time and the storage\ncost for large-scale video datasets.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}